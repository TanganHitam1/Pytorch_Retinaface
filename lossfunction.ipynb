{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\.conda\\envs\\retinaface\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.retinaface import RetinaFace\n",
    "from data import cfg_re50\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from layers.functions.prior_box import PriorBox\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn import DataParallel\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "from utils.box_utils import decode, decode_landm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    print('remove prefix \\'{}\\''.format(prefix))\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove prefix 'module.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weights = './weights/Resnet50/b8/lr0.001/optSGD/Resnet50_b8_lr1.0000000000000003e-05_optSGD_Final.pth'\n",
    "model = RetinaFace(cfg=cfg_re50, phase='test')\n",
    "device = torch.cuda.current_device()\n",
    "pretrained_dict = torch.load(pretrained_weights, map_location=lambda storage, loc: storage.cuda(device))\n",
    "pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "model.load_state_dict(pretrained_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "model = DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./curve/test6.jpg\"\n",
    "img_raw = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "img = np.float32(img_raw)\n",
    "im_height, im_width, _ = img.shape\n",
    "scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "img -= (104, 117, 123)\n",
    "img = img.transpose(2, 0, 1)\n",
    "img = torch.from_numpy(img).unsqueeze(0)\n",
    "img = img.to(device)\n",
    "scale = scale.to(device)\n",
    "\n",
    "# (loc, conf, landms), embedding = model(img)  # forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((cfg_re50['image_size'], cfg_re50['image_size'])),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = transform(img_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loc, conf, landms), embedding = model(img)  # forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5469,  1.5489, -0.8814,  0.2299],\n",
       "          [ 0.9827,  1.7706, -1.4537, -0.1859],\n",
       "          [-0.1422,  1.6518, -0.3592, -0.6741],\n",
       "          ...,\n",
       "          [-0.4425, -0.1530, -0.4372, -0.1865],\n",
       "          [-0.9754, -0.5551, -0.7518,  0.7454],\n",
       "          [-0.5474, -0.0828, -1.3114,  0.0774]]], device='cuda:0',\n",
       "        grad_fn=<CatBackward>),\n",
       " torch.Size([24192, 4]),\n",
       " tensor([[[9.9936e-01, 6.3897e-04],\n",
       "          [9.9952e-01, 4.8082e-04],\n",
       "          [9.9890e-01, 1.0987e-03],\n",
       "          ...,\n",
       "          [9.9994e-01, 6.1348e-05],\n",
       "          [9.9997e-01, 3.4573e-05],\n",
       "          [9.9999e-01, 1.2661e-05]]], device='cuda:0',\n",
       "        grad_fn=<SoftmaxBackward>),\n",
       " torch.Size([24192, 2]),\n",
       " tensor([[[-1.2888, -1.7257,  2.9366,  ...,  4.3994,  2.2572,  4.3963],\n",
       "          [-0.7890, -1.0828,  2.5034,  ...,  3.7872,  2.2856,  3.5980],\n",
       "          [-2.2388, -1.5540,  2.1273,  ...,  3.7382,  1.7620,  3.6749],\n",
       "          ...,\n",
       "          [-1.4398, -1.3708,  0.1921,  ...,  2.3055,  0.0543,  1.9738],\n",
       "          [-1.2005, -2.1508,  1.4473,  ...,  2.4031,  0.9785,  2.0765],\n",
       "          [-1.2106, -1.8426,  1.1626,  ...,  2.7630,  0.9122,  2.4699]]],\n",
       "        device='cuda:0', grad_fn=<CatBackward>),\n",
       " torch.Size([24192, 10]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc, loc.squeeze(0).shape, conf, conf.squeeze(0).shape, landms, landms.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer2',\n",
       "              tensor([[[[0.0000e+00, 0.0000e+00, 8.1872e-01,  ..., 3.4432e-01,\n",
       "                         0.0000e+00, 8.5564e-01],\n",
       "                        [6.4227e-03, 0.0000e+00, 6.1718e-02,  ..., 0.0000e+00,\n",
       "                         0.0000e+00, 5.9092e-01],\n",
       "                        [1.2926e+00, 1.9650e-01, 4.1889e-01,  ..., 0.0000e+00,\n",
       "                         5.9328e-01, 3.3760e-01],\n",
       "                        ...,\n",
       "                        [1.0651e+00, 1.3693e+00, 1.0829e+00,  ..., 3.9240e-01,\n",
       "                         4.5326e-02, 3.8854e-02],\n",
       "                        [1.0748e+00, 1.3686e+00, 2.0782e+00,  ..., 1.3366e+00,\n",
       "                         9.5888e-01, 4.4663e-01],\n",
       "                        [6.5448e-01, 1.6159e-01, 2.1342e-02,  ..., 0.0000e+00,\n",
       "                         3.0699e-02, 6.6310e-01]],\n",
       "              \n",
       "                       [[2.1205e+00, 3.5062e+00, 2.2774e+00,  ..., 1.9434e+00,\n",
       "                         2.2370e+00, 9.0633e-01],\n",
       "                        [1.9134e+00, 2.2720e+00, 2.5270e+00,  ..., 3.0432e+00,\n",
       "                         2.3389e+00, 2.2617e+00],\n",
       "                        [1.6225e+00, 1.0676e+00, 9.1095e-01,  ..., 3.4528e-01,\n",
       "                         8.5752e-01, 1.1336e+00],\n",
       "                        ...,\n",
       "                        [1.5909e+00, 9.0800e-01, 1.8050e-01,  ..., 0.0000e+00,\n",
       "                         0.0000e+00, 1.8338e-01],\n",
       "                        [1.3540e+00, 6.3937e-01, 1.4708e+00,  ..., 9.6710e-01,\n",
       "                         1.1923e+00, 1.2405e+00],\n",
       "                        [2.6828e+00, 2.5462e+00, 2.7926e+00,  ..., 2.0804e+00,\n",
       "                         2.2008e+00, 2.1787e+00]],\n",
       "              \n",
       "                       [[1.0848e+00, 5.0751e-01, 4.3849e-01,  ..., 0.0000e+00,\n",
       "                         0.0000e+00, 0.0000e+00],\n",
       "                        [5.1698e-01, 0.0000e+00, 0.0000e+00,  ..., 2.7044e-01,\n",
       "                         0.0000e+00, 0.0000e+00],\n",
       "                        [1.1853e+00, 1.7937e+00, 6.2859e-01,  ..., 6.1208e-01,\n",
       "                         5.7329e-01, 1.8130e+00],\n",
       "                        ...,\n",
       "                        [1.7653e+00, 1.8148e+00, 0.0000e+00,  ..., 8.9285e-01,\n",
       "                         0.0000e+00, 1.9220e+00],\n",
       "                        [3.8232e+00, 4.6126e+00, 3.2738e+00,  ..., 3.3572e+00,\n",
       "                         2.2249e+00, 3.5571e+00],\n",
       "                        [6.8374e-01, 3.1408e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "                         0.0000e+00, 0.0000e+00]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1.3757e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "                         1.9216e-01, 1.5044e+00],\n",
       "                        [9.7478e-01, 0.0000e+00, 2.0911e-01,  ..., 5.5846e-01,\n",
       "                         6.6150e-01, 2.8594e-01],\n",
       "                        [1.2507e+00, 1.8012e-01, 3.4755e-01,  ..., 1.0724e+00,\n",
       "                         3.8799e-01, 3.3514e-01],\n",
       "                        ...,\n",
       "                        [1.3633e+00, 4.1784e-01, 9.0864e-02,  ..., 1.3459e+00,\n",
       "                         5.1437e-01, 4.1159e-01],\n",
       "                        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "                         0.0000e+00, 4.1238e-02],\n",
       "                        [9.1398e-01, 7.3960e-01, 6.1220e-01,  ..., 7.2915e-01,\n",
       "                         7.3924e-01, 1.2708e+00]],\n",
       "              \n",
       "                       [[2.0712e+00, 2.9388e+00, 2.2402e+00,  ..., 2.1883e+00,\n",
       "                         2.5115e+00, 1.4647e+00],\n",
       "                        [1.3198e+00, 0.0000e+00, 0.0000e+00,  ..., 4.8041e-02,\n",
       "                         6.6392e-01, 1.4579e+00],\n",
       "                        [2.0399e+00, 1.2216e+00, 1.3712e-01,  ..., 3.1287e-02,\n",
       "                         6.7955e-01, 3.4674e+00],\n",
       "                        ...,\n",
       "                        [2.2068e+00, 8.5187e-01, 0.0000e+00,  ..., 1.2537e-01,\n",
       "                         0.0000e+00, 2.4822e+00],\n",
       "                        [2.7952e+00, 2.4469e+00, 2.5638e+00,  ..., 2.0331e+00,\n",
       "                         2.0789e+00, 4.2882e+00],\n",
       "                        [1.1094e+00, 0.0000e+00, 8.0148e-02,  ..., 6.7745e-02,\n",
       "                         3.5615e-01, 1.6336e-01]],\n",
       "              \n",
       "                       [[3.9374e+00, 7.3178e-01, 0.0000e+00,  ..., 1.6236e-01,\n",
       "                         2.3286e-01, 1.3200e+00],\n",
       "                        [4.0536e+00, 4.1179e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "                         1.7511e-03, 2.2215e+00],\n",
       "                        [4.6753e+00, 2.1952e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "                         0.0000e+00, 3.5299e+00],\n",
       "                        ...,\n",
       "                        [4.4764e+00, 1.2702e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "                         0.0000e+00, 2.5045e+00],\n",
       "                        [4.2022e+00, 1.4083e+00, 1.7592e-01,  ..., 8.9036e-01,\n",
       "                         6.3488e-01, 1.5400e+00],\n",
       "                        [3.0577e+00, 1.5816e-01, 0.0000e+00,  ..., 2.8890e-01,\n",
       "                         2.7506e-01, 2.0063e+00]]]], device='cuda:0',\n",
       "                     grad_fn=<ReluBackward1>)),\n",
       "             ('layer3',\n",
       "              tensor([[[[2.2571, 2.2311, 2.5362,  ..., 2.1197, 2.1119, 2.0526],\n",
       "                        [2.5035, 1.5798, 1.6519,  ..., 1.7039, 0.5436, 0.7348],\n",
       "                        [2.2979, 2.0589, 2.0078,  ..., 2.3939, 1.1849, 2.3379],\n",
       "                        ...,\n",
       "                        [1.1159, 0.6588, 0.4025,  ..., 1.1009, 0.9336, 0.0000],\n",
       "                        [2.1686, 1.8049, 0.7138,  ..., 1.6565, 1.6900, 0.1856],\n",
       "                        [1.7814, 1.8887, 1.5764,  ..., 1.7411, 2.0525, 1.1544]],\n",
       "              \n",
       "                       [[0.5422, 0.2990, 1.2609,  ..., 0.3048, 0.7779, 0.4887],\n",
       "                        [0.5099, 0.1066, 0.4241,  ..., 0.0000, 0.6630, 0.0000],\n",
       "                        [0.7196, 0.1552, 1.1309,  ..., 0.6442, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.3174, 0.3394, 1.4708,  ..., 0.4652, 0.5599, 0.0000],\n",
       "                        [0.2588, 0.0000, 1.3921,  ..., 0.4164, 0.7083, 0.0000],\n",
       "                        [0.4996, 0.2286, 0.5617,  ..., 0.1732, 0.4736, 0.0000]],\n",
       "              \n",
       "                       [[0.0717, 1.2647, 0.9368,  ..., 0.4999, 1.0504, 0.1523],\n",
       "                        [0.8791, 1.5043, 1.5922,  ..., 0.9083, 0.7625, 0.0000],\n",
       "                        [0.6249, 0.6295, 0.0000,  ..., 0.7334, 0.8967, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.4341,  ..., 1.0205, 3.0918, 0.6996],\n",
       "                        [0.8786, 1.4339, 1.7993,  ..., 1.8500, 3.5173, 1.1017],\n",
       "                        [0.8764, 1.6300, 2.3592,  ..., 2.2651, 1.9382, 1.6534]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0.6921, 0.3768, 0.0000,  ..., 1.5481, 1.0458, 2.1159],\n",
       "                        [0.5270, 0.7238, 1.0375,  ..., 1.0562, 0.5309, 2.7647],\n",
       "                        [0.0000, 0.3793, 0.0000,  ..., 0.0000, 0.0000, 1.1861],\n",
       "                        ...,\n",
       "                        [0.9864, 1.4067, 1.3569,  ..., 0.1231, 0.0059, 1.0138],\n",
       "                        [1.5968, 2.2882, 1.3320,  ..., 1.8000, 0.3404, 1.9638],\n",
       "                        [2.1043, 2.4546, 0.2556,  ..., 2.3295, 2.1659, 2.2271]],\n",
       "              \n",
       "                       [[0.3235, 0.7841, 0.5782,  ..., 0.2474, 0.6854, 0.4108],\n",
       "                        [0.6026, 1.4671, 0.9457,  ..., 1.2932, 2.0182, 0.6207],\n",
       "                        [0.0000, 1.4753, 0.0000,  ..., 0.0000, 0.8601, 0.0000],\n",
       "                        ...,\n",
       "                        [0.3100, 0.8492, 1.4539,  ..., 0.2539, 1.4576, 2.0591],\n",
       "                        [0.3549, 1.4364, 3.1976,  ..., 1.3925, 2.4582, 2.5857],\n",
       "                        [0.0000, 0.8997, 0.7663,  ..., 0.6146, 0.3352, 1.4566]],\n",
       "              \n",
       "                       [[1.3895, 2.9975, 0.9581,  ..., 0.6069, 0.0413, 1.0397],\n",
       "                        [2.1823, 2.6476, 1.3576,  ..., 2.1317, 1.4791, 1.3398],\n",
       "                        [1.7585, 3.6635, 1.7170,  ..., 1.4321, 0.9887, 0.4539],\n",
       "                        ...,\n",
       "                        [1.8443, 2.2038, 1.2513,  ..., 1.6974, 1.3782, 1.4652],\n",
       "                        [1.8817, 3.0811, 2.8436,  ..., 2.4016, 1.2712, 1.9480],\n",
       "                        [1.4198, 1.8088, 0.4824,  ..., 0.0123, 0.0000, 1.2054]]]],\n",
       "                     device='cuda:0', grad_fn=<ReluBackward1>)),\n",
       "             ('layer4',\n",
       "              tensor([[[[0.0710, 0.5885, 1.5663,  ..., 2.0308, 2.1395, 2.4682],\n",
       "                        [0.1243, 0.0000, 0.3649,  ..., 0.0000, 0.3005, 0.4245],\n",
       "                        [0.7900, 0.7971, 1.0727,  ..., 0.0000, 0.0000, 0.3047],\n",
       "                        ...,\n",
       "                        [1.4366, 1.0539, 0.7332,  ..., 0.0365, 1.2494, 0.9550],\n",
       "                        [1.9746, 2.0293, 0.6127,  ..., 0.6417, 1.2643, 1.0407],\n",
       "                        [1.9142, 1.2008, 0.8996,  ..., 0.3239, 1.4140, 1.1496]],\n",
       "              \n",
       "                       [[0.3497, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.4381],\n",
       "                        [0.8152, 0.0000, 0.0000,  ..., 0.5053, 0.0868, 0.9682],\n",
       "                        [0.9059, 0.4991, 0.9231,  ..., 0.7791, 0.9768, 1.2625],\n",
       "                        ...,\n",
       "                        [0.0556, 0.1921, 0.8578,  ..., 0.6974, 0.0000, 1.6735],\n",
       "                        [0.0000, 0.0253, 0.7144,  ..., 0.0000, 0.8407, 2.1449],\n",
       "                        [0.9496, 0.7147, 0.9501,  ..., 0.9624, 1.6499, 2.0211]],\n",
       "              \n",
       "                       [[0.0000, 0.7779, 0.1636,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.2546, 0.4168, 0.6722,  ..., 0.5122, 0.6291, 0.0000],\n",
       "                        [0.2669, 0.4541, 0.5377,  ..., 1.7279, 1.0391, 0.2201],\n",
       "                        ...,\n",
       "                        [0.9027, 0.8437, 0.5027,  ..., 0.3640, 1.3233, 0.0000],\n",
       "                        [0.9467, 1.1280, 0.6306,  ..., 0.5511, 1.1099, 0.2246],\n",
       "                        [0.3161, 1.8776, 0.9065,  ..., 0.3052, 0.4180, 0.0000]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0.4411, 0.4524, 0.3646,  ..., 0.8442, 0.4397, 0.0000],\n",
       "                        [0.2891, 1.0051, 0.5240,  ..., 0.0000, 0.2430, 0.0000],\n",
       "                        [0.4127, 1.3813, 1.5478,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.2291, 0.1472, 0.1706,  ..., 0.0000, 1.3634, 0.0443],\n",
       "                        [0.9702, 0.6285, 0.9465,  ..., 0.2161, 0.4639, 0.0000],\n",
       "                        [0.2370, 0.0000, 0.0000,  ..., 0.0198, 0.0000, 0.0000]],\n",
       "              \n",
       "                       [[0.0000, 0.0000, 0.5426,  ..., 0.1200, 0.3985, 1.2158],\n",
       "                        [0.1987, 0.0000, 1.4528,  ..., 0.6545, 1.3670, 1.2830],\n",
       "                        [0.0000, 0.2298, 1.0677,  ..., 0.5651, 0.6299, 1.6019],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 1.2850, 0.4645, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.2446,  ..., 0.9415, 0.8481, 1.0600],\n",
       "                        [0.0000, 0.0000, 0.6507,  ..., 0.3370, 0.6081, 0.6428]],\n",
       "              \n",
       "                       [[2.4887, 2.8664, 1.9875,  ..., 1.9073, 2.1842, 1.7447],\n",
       "                        [1.4615, 0.0511, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [1.7727, 0.8120, 0.2293,  ..., 0.5504, 0.0000, 0.2995],\n",
       "                        ...,\n",
       "                        [0.6123, 1.2235, 0.0000,  ..., 0.0000, 0.7346, 0.4528],\n",
       "                        [0.3834, 0.5897, 0.0000,  ..., 0.0000, 0.4088, 0.0000],\n",
       "                        [0.6906, 0.0870, 0.0000,  ..., 0.0000, 0.0000, 0.0815]]]],\n",
       "                     device='cuda:0', grad_fn=<ReluBackward1>))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0710, 0.5885, 1.5663,  ..., 2.0308, 2.1395, 2.4682],\n",
       "           [0.1243, 0.0000, 0.3649,  ..., 0.0000, 0.3005, 0.4245],\n",
       "           [0.7900, 0.7971, 1.0727,  ..., 0.0000, 0.0000, 0.3047],\n",
       "           ...,\n",
       "           [1.4366, 1.0539, 0.7332,  ..., 0.0365, 1.2494, 0.9550],\n",
       "           [1.9746, 2.0293, 0.6127,  ..., 0.6417, 1.2643, 1.0407],\n",
       "           [1.9142, 1.2008, 0.8996,  ..., 0.3239, 1.4140, 1.1496]],\n",
       " \n",
       "          [[0.3497, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.4381],\n",
       "           [0.8152, 0.0000, 0.0000,  ..., 0.5053, 0.0868, 0.9682],\n",
       "           [0.9059, 0.4991, 0.9231,  ..., 0.7791, 0.9768, 1.2625],\n",
       "           ...,\n",
       "           [0.0556, 0.1921, 0.8578,  ..., 0.6974, 0.0000, 1.6735],\n",
       "           [0.0000, 0.0253, 0.7144,  ..., 0.0000, 0.8407, 2.1449],\n",
       "           [0.9496, 0.7147, 0.9501,  ..., 0.9624, 1.6499, 2.0211]],\n",
       " \n",
       "          [[0.0000, 0.7779, 0.1636,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.2546, 0.4168, 0.6722,  ..., 0.5122, 0.6291, 0.0000],\n",
       "           [0.2669, 0.4541, 0.5377,  ..., 1.7279, 1.0391, 0.2201],\n",
       "           ...,\n",
       "           [0.9027, 0.8437, 0.5027,  ..., 0.3640, 1.3233, 0.0000],\n",
       "           [0.9467, 1.1280, 0.6306,  ..., 0.5511, 1.1099, 0.2246],\n",
       "           [0.3161, 1.8776, 0.9065,  ..., 0.3052, 0.4180, 0.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.4411, 0.4524, 0.3646,  ..., 0.8442, 0.4397, 0.0000],\n",
       "           [0.2891, 1.0051, 0.5240,  ..., 0.0000, 0.2430, 0.0000],\n",
       "           [0.4127, 1.3813, 1.5478,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.2291, 0.1472, 0.1706,  ..., 0.0000, 1.3634, 0.0443],\n",
       "           [0.9702, 0.6285, 0.9465,  ..., 0.2161, 0.4639, 0.0000],\n",
       "           [0.2370, 0.0000, 0.0000,  ..., 0.0198, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.5426,  ..., 0.1200, 0.3985, 1.2158],\n",
       "           [0.1987, 0.0000, 1.4528,  ..., 0.6545, 1.3670, 1.2830],\n",
       "           [0.0000, 0.2298, 1.0677,  ..., 0.5651, 0.6299, 1.6019],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.2850, 0.4645, 0.0000],\n",
       "           [0.0000, 0.0000, 0.2446,  ..., 0.9415, 0.8481, 1.0600],\n",
       "           [0.0000, 0.0000, 0.6507,  ..., 0.3370, 0.6081, 0.6428]],\n",
       " \n",
       "          [[2.4887, 2.8664, 1.9875,  ..., 1.9073, 2.1842, 1.7447],\n",
       "           [1.4615, 0.0511, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [1.7727, 0.8120, 0.2293,  ..., 0.5504, 0.0000, 0.2995],\n",
       "           ...,\n",
       "           [0.6123, 1.2235, 0.0000,  ..., 0.0000, 0.7346, 0.4528],\n",
       "           [0.3834, 0.5897, 0.0000,  ..., 0.0000, 0.4088, 0.0000],\n",
       "           [0.6906, 0.0870, 0.0000,  ..., 0.0000, 0.0000, 0.0815]]]],\n",
       "        device='cuda:0', grad_fn=<ReluBackward1>),\n",
       " torch.Size([1, 2048, 18, 32]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding['layer4'], embedding['layer4'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding['layer4'].squeeze()  # Ambil embedding dari 'layer4' dan hilangkan dimensi yang tidak diperlukan\n",
    "embedding_dim = embedding.numel()  # Hitung jumlah elemen di tensor\n",
    "embedding = embedding.view(-1, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0710, 0.5885, 1.5663,  ..., 0.0000, 0.0000, 0.0815]],\n",
       "        device='cuda:0', grad_fn=<ViewBackward>),\n",
       " torch.Size([1, 1179648]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding, embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1179648])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_input = embedding.view(512, -1)  # Reshape into a 512x(-1) tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_input = arcface_input.mean(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_input = arcface_input.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6002, 0.5812, 0.5782, 0.5321, 0.5659, 0.5577, 0.5715, 0.5549, 0.6095,\n",
       "          0.5565, 0.5690, 0.5544, 0.5931, 0.5938, 0.5638, 0.5528, 0.5873, 0.5882,\n",
       "          0.5588, 0.5771, 0.5747, 0.5886, 0.5908, 0.5687, 0.5742, 0.5536, 0.5487,\n",
       "          0.5708, 0.5772, 0.5658, 0.5599, 0.5731, 0.5335, 0.5819, 0.5713, 0.5600,\n",
       "          0.5526, 0.5822, 0.5849, 0.5518, 0.6019, 0.5514, 0.5640, 0.5718, 0.5652,\n",
       "          0.5933, 0.5902, 0.5630, 0.5729, 0.5863, 0.5416, 0.5859, 0.5479, 0.5807,\n",
       "          0.5731, 0.5833, 0.5566, 0.5771, 0.5758, 0.5579, 0.5547, 0.5782, 0.5397,\n",
       "          0.5894, 0.5672, 0.5398, 0.5815, 0.5902, 0.5727, 0.5823, 0.5642, 0.5882,\n",
       "          0.5952, 0.5553, 0.5620, 0.5530, 0.5766, 0.5651, 0.5687, 0.5798, 0.5625,\n",
       "          0.5879, 0.5936, 0.5882, 0.5555, 0.5601, 0.5734, 0.5665, 0.5410, 0.5877,\n",
       "          0.5883, 0.5782, 0.5718, 0.5707, 0.5433, 0.5331, 0.5896, 0.5521, 0.5672,\n",
       "          0.5503, 0.5938, 0.5852, 0.5691, 0.5887, 0.5613, 0.5809, 0.5960, 0.5737,\n",
       "          0.5585, 0.5649, 0.5681, 0.5836, 0.5891, 0.5664, 0.5841, 0.5780, 0.5790,\n",
       "          0.5786, 0.5743, 0.5876, 0.5727, 0.5923, 0.5708, 0.5668, 0.5516, 0.5851,\n",
       "          0.5734, 0.5477, 0.5458, 0.5788, 0.5781, 0.5784, 0.5656, 0.5800, 0.5610,\n",
       "          0.5553, 0.5764, 0.5805, 0.5578, 0.5659, 0.5656, 0.5410, 0.5792, 0.5596,\n",
       "          0.5593, 0.5579, 0.5649, 0.5217, 0.5777, 0.5592, 0.5566, 0.5765, 0.5858,\n",
       "          0.5765, 0.5695, 0.5866, 0.5610, 0.5421, 0.5426, 0.5680, 0.5547, 0.5752,\n",
       "          0.5807, 0.5869, 0.5850, 0.5565, 0.5515, 0.5830, 0.5581, 0.5695, 0.5613,\n",
       "          0.5891, 0.5621, 0.5773, 0.5799, 0.5694, 0.5511, 0.5468, 0.5801, 0.5932,\n",
       "          0.5700, 0.5590, 0.5782, 0.5778, 0.5869, 0.5564, 0.5632, 0.5501, 0.5627,\n",
       "          0.5631, 0.5955, 0.5762, 0.5599, 0.5801, 0.5917, 0.6129, 0.5781, 0.5768,\n",
       "          0.5623, 0.5852, 0.5562, 0.5545, 0.5701, 0.5896, 0.5550, 0.5865, 0.5837,\n",
       "          0.5735, 0.5644, 0.5567, 0.6021, 0.5802, 0.5722, 0.5850, 0.5613, 0.5611,\n",
       "          0.5883, 0.5703, 0.5609, 0.5656, 0.5753, 0.5644, 0.5543, 0.5710, 0.5584,\n",
       "          0.5580, 0.5720, 0.5731, 0.5691, 0.5688, 0.5559, 0.6002, 0.5689, 0.5627,\n",
       "          0.5479, 0.5537, 0.5788, 0.5699, 0.5779, 0.5495, 0.5498, 0.5939, 0.5621,\n",
       "          0.5481, 0.5490, 0.5813, 0.5690, 0.5711, 0.5794, 0.5742, 0.5815, 0.5899,\n",
       "          0.5573, 0.5634, 0.5546, 0.5905, 0.5649, 0.5612, 0.5697, 0.5774, 0.5611,\n",
       "          0.5686, 0.5797, 0.5749, 0.5456, 0.5722, 0.5713, 0.5484, 0.5772, 0.5399,\n",
       "          0.5475, 0.5824, 0.5698, 0.5565, 0.5769, 0.5844, 0.5528, 0.5722, 0.5860,\n",
       "          0.5832, 0.5750, 0.5713, 0.5561, 0.5676, 0.5628, 0.5876, 0.5903, 0.5634,\n",
       "          0.5689, 0.5675, 0.5710, 0.5827, 0.5699, 0.5603, 0.5605, 0.5724, 0.5594,\n",
       "          0.5758, 0.5823, 0.5575, 0.5464, 0.5569, 0.5808, 0.5978, 0.5934, 0.5549,\n",
       "          0.5784, 0.5780, 0.5766, 0.5622, 0.5701, 0.5743, 0.5696, 0.5775, 0.5643,\n",
       "          0.5909, 0.5723, 0.5364, 0.5752, 0.5515, 0.5860, 0.5711, 0.5829, 0.5924,\n",
       "          0.5909, 0.5829, 0.5724, 0.5634, 0.5703, 0.5416, 0.5657, 0.5704, 0.5495,\n",
       "          0.5558, 0.5663, 0.5497, 0.5897, 0.5489, 0.5457, 0.5589, 0.5691, 0.5709,\n",
       "          0.5437, 0.5732, 0.5335, 0.5530, 0.5758, 0.5915, 0.5744, 0.5587, 0.5850,\n",
       "          0.5500, 0.5942, 0.5794, 0.5708, 0.5770, 0.5668, 0.5635, 0.5669, 0.5546,\n",
       "          0.5487, 0.5495, 0.5799, 0.5750, 0.5501, 0.5933, 0.5739, 0.5799, 0.5831,\n",
       "          0.5777, 0.5697, 0.5760, 0.5694, 0.5337, 0.5625, 0.5652, 0.5557, 0.5815,\n",
       "          0.5973, 0.5649, 0.5589, 0.5490, 0.5752, 0.5520, 0.5829, 0.5865, 0.5760,\n",
       "          0.5730, 0.5729, 0.5617, 0.5571, 0.5673, 0.5538, 0.5628, 0.5851, 0.5652,\n",
       "          0.6028, 0.6086, 0.5553, 0.5836, 0.5721, 0.5520, 0.5767, 0.5829, 0.5666,\n",
       "          0.5647, 0.5659, 0.5820, 0.5519, 0.6005, 0.5730, 0.5697, 0.5434, 0.5760,\n",
       "          0.5638, 0.5741, 0.5909, 0.5939, 0.5624, 0.5750, 0.5478, 0.5611, 0.5809,\n",
       "          0.5609, 0.5522, 0.5771, 0.5805, 0.5614, 0.5682, 0.5609, 0.5840, 0.5705,\n",
       "          0.5736, 0.5896, 0.5801, 0.5531, 0.5698, 0.5751, 0.5618, 0.5499, 0.5645,\n",
       "          0.5676, 0.5584, 0.5684, 0.5922, 0.5553, 0.5500, 0.5977, 0.5745, 0.5648,\n",
       "          0.5845, 0.5546, 0.5827, 0.5755, 0.5934, 0.5694, 0.5392, 0.5545, 0.5845,\n",
       "          0.5968, 0.5514, 0.5747, 0.5811, 0.5737, 0.5638, 0.5678, 0.5855, 0.5698,\n",
       "          0.5751, 0.6092, 0.5792, 0.5601, 0.5784, 0.5779, 0.5928, 0.5802, 0.5860,\n",
       "          0.5636, 0.5416, 0.5846, 0.5824, 0.5636, 0.5639, 0.6124, 0.5670, 0.5725,\n",
       "          0.5867, 0.5767, 0.5960, 0.5599, 0.5522, 0.5605, 0.5647, 0.5568, 0.5807,\n",
       "          0.5638, 0.5637, 0.5707, 0.5508, 0.5739, 0.5561, 0.5764, 0.5788, 0.5672,\n",
       "          0.6011, 0.5521, 0.5759, 0.5599, 0.5735, 0.5724, 0.5507, 0.5648]],\n",
       "        device='cuda:0', grad_fn=<TBackward>),\n",
       " torch.Size([1, 512]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcface_input, arcface_input.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retinaface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
